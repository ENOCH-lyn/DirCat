import os
import argparse
import pyperclip
from pathlib import Path
import fnmatch
from datetime import datetime
from .config import DEFAULT_EXCLUDE_PATTERNS, LANGUAGE_MAP


DEFAULT_ENCODING_CANDIDATES = [
    'utf-8',
    'utf-8-sig',
    'gb18030',
    'gbk',
    'big5',
    'shift_jis',
    'latin-1'
]


def _detect_bom_encoding(file_path: Path):
    """æ£€æµ‹æ–‡ä»¶çš„ BOM å¹¶è¿”å›é¦–é€‰ç¼–ç ,æœªæ£€æµ‹åˆ°åˆ™è¿”å› Noneã€‚"""
    try:
        with open(file_path, 'rb') as f:
            raw = f.read(4)
    except IOError:
        return None

    if raw.startswith(b'\xff\xfe\x00\x00'):
        return 'utf-32'
    if raw.startswith(b'\x00\x00\xfe\xff'):
        return 'utf-32'
    if raw.startswith(b'\xff\xfe'):
        return 'utf-16'
    if raw.startswith(b'\xfe\xff'):
        return 'utf-16'
    if raw.startswith(b'\xef\xbb\xbf'):
        return 'utf-8-sig'
    return None


def _prepare_encoding_sequence(file_path: Path, fallback_candidates=None):
    """æ ¹æ® BOM ä¼˜å…ˆçº§æ„å»ºç¼–ç å°è¯•é¡ºåºã€‚"""
    fallback_candidates = fallback_candidates or DEFAULT_ENCODING_CANDIDATES
    sequence = []

    bom_encoding = _detect_bom_encoding(file_path)
    if bom_encoding:
        sequence.append(bom_encoding)

    for encoding in fallback_candidates:
        if encoding not in sequence:
            sequence.append(encoding)

    return sequence


def _get_ignore_patterns(root_path, encodings=None):
    """ä» .dircatignore æ–‡ä»¶åŠ è½½å¿½ç•¥æ¨¡å¼,é€ä¸ªå°è¯•æä¾›çš„ç¼–ç ."""
    ignore_file = Path(root_path) / '.dircatignore'
    if not ignore_file.is_file():
        return set()

    encodings = encodings or DEFAULT_ENCODING_CANDIDATES

    for encoding in _prepare_encoding_sequence(ignore_file, encodings):
        try:
            with open(ignore_file, 'r', encoding=encoding) as f:
                patterns = set()
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        patterns.add(line)
                return patterns
        except UnicodeDecodeError:
            continue
        except IOError:
            break

    return set()


def _read_file_content(file_path, base_path, encodings=None):
    """è¯»å–å¹¶æ ¼å¼åŒ–å•ä¸ªæ–‡ä»¶çš„å†…å®¹,åœ¨å‰é¢åŠ ä¸Šæ–‡ä»¶è·¯å¾„æ ‡é¢˜,æ”¯æŒå¤šç¼–ç ã€‚"""
    encodings = encodings or DEFAULT_ENCODING_CANDIDATES
    relative_path = file_path.relative_to(base_path)
    header = f"--- æ–‡ä»¶: {relative_path.as_posix()} ---\n"
    
    # å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶ï¼ˆåœ¨å°è¯•æ–‡æœ¬è§£ç å‰ï¼‰
    try:
        with open(file_path, 'rb') as f:
            chunk = f.read(1024)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æœ¬ç¼–ç çš„ BOMï¼Œå¦‚æœæœ‰åˆ™ä¸æ˜¯äºŒè¿›åˆ¶
            has_text_bom = (
                chunk.startswith(b'\xff\xfe') or  # UTF-16 LE
                chunk.startswith(b'\xfe\xff') or  # UTF-16 BE
                chunk.startswith(b'\xff\xfe\x00\x00') or  # UTF-32 LE
                chunk.startswith(b'\x00\x00\xfe\xff') or  # UTF-32 BE
                chunk.startswith(b'\xef\xbb\xbf')  # UTF-8 BOM
            )
            
            # å¦‚æœæœ‰æ–‡æœ¬ BOMï¼Œè·³è¿‡äºŒè¿›åˆ¶æ£€æŸ¥
            if not has_text_bom:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ç©ºå­—èŠ‚ï¼Œè¿™æ˜¯äºŒè¿›åˆ¶æ–‡ä»¶çš„æ˜ç¡®æ ‡å¿—
                if b'\x00' in chunk:
                    file_size = file_path.stat().st_size
                    size_str = f"{file_size:,} bytes" if file_size < 1024 else f"{file_size / 1024:.2f} KB"
                    return f"{header}*** äºŒè¿›åˆ¶æ–‡ä»¶ ({size_str}) ***\n\n"
    except:
        pass
    
    # å°è¯•ç”¨æ‰€æœ‰ç¼–ç è¯»å–æ–‡æœ¬æ–‡ä»¶
    for encoding in _prepare_encoding_sequence(file_path, encodings):
        try:
            with open(file_path, 'r', encoding=encoding) as file:
                content = file.read()
                lang = LANGUAGE_MAP.get(file_path.suffix, '')
                opening = f"```{lang}\n" if lang else "```\n"
                return f"{header}{opening}{content}\n```\n\n"
        except UnicodeDecodeError:
            continue
        except IOError as e:
            return f"{header}*** æ— æ³•è¯»å–æ–‡ä»¶: {e} ***\n\n"
    
    # å¦‚æœä¸æ˜¯æ˜æ˜¾çš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œè¿”å›ç¼–ç å¤±è´¥æç¤º
    return f"{header}*** æ— æ³•ä½¿ç”¨ä»¥ä¸‹ç¼–ç è¯»å–æ–‡ä»¶: {', '.join(encodings)} ***\n\n"


def _is_excluded(path, patterns, base_path):
    """æ£€æŸ¥è·¯å¾„æ˜¯å¦åŒ¹é…ä»»ä½•å¿½ç•¥æ¨¡å¼ã€‚"""
    relative_path_str = str(path.relative_to(base_path))
    path_name = path.name
    
    for pattern in patterns:
        if pattern.endswith('/'):
            if path.is_dir() and (relative_path_str + '/').startswith(pattern):
                return True
        elif fnmatch.fnmatch(path_name, pattern):
            return True
        elif fnmatch.fnmatch(relative_path_str, pattern):
            return True
            
    return False

def _build_tree_recursive(current_path, base_path, all_exclude_patterns, max_items, 
                          prefix="", is_last=True, files_to_read=None):
    """é€’å½’æ„å»º ASCII æ ‘å½¢ç»“æ„ï¼Œè¿”å›æ ‘å½¢å­—ç¬¦ä¸²åˆ—è¡¨ã€‚"""
    if files_to_read is None:
        files_to_read = []
    
    lines = []
    
    # å½“å‰ç›®å½•å
    if current_path == base_path:
        lines.append(f"{current_path.name}/\n")
    
    try:
        entries = list(current_path.iterdir())
    except PermissionError:
        return lines, files_to_read
    
    # è¿‡æ»¤æ’é™¤é¡¹
    dirs = sorted([e for e in entries if e.is_dir() and not _is_excluded(e, all_exclude_patterns, base_path)])
    files = sorted([e for e in entries if e.is_file() and not _is_excluded(e, all_exclude_patterns, base_path)])
    
    # æ£€æŸ¥æ•°é‡é™åˆ¶
    if len(dirs) + len(files) > max_items:
        rel_path = current_path.relative_to(base_path)
        lines.append(f"{prefix}--- æ–‡ä»¶å¤¹ '{rel_path}' å› ä¸ºåŒ…å«è¶…è¿‡ {max_items} ä¸ªé¡¹ç›®è€Œè¢«è·³è¿‡ ---\n")
        return lines, files_to_read
    
    all_entries = dirs + files
    
    for i, entry in enumerate(all_entries):
        is_last_entry = (i == len(all_entries) - 1)
        connector = "â””â”€â”€ " if is_last_entry else "â”œâ”€â”€ "
        
        if entry.is_dir():
            lines.append(f"{prefix}{connector}{entry.name}/\n")
            # é€’å½’å­ç›®å½•
            extension = "    " if is_last_entry else "â”‚   "
            sub_lines, files_to_read = _build_tree_recursive(
                entry, base_path, all_exclude_patterns, max_items,
                prefix + extension, is_last_entry, files_to_read
            )
            lines.extend(sub_lines)
        else:
            lines.append(f"{prefix}{connector}{entry.name}\n")
            files_to_read.append(entry)
    
    return lines, files_to_read


def generate_tree_output(root_path, user_exclude, max_items, encodings=None,
                         style="emoji", include_content=True):
    """ç”Ÿæˆç›®å½•ç»“æ„(ä¸¤ç§æ˜¾ç¤ºæ¨¡å¼)å’Œå¯é€‰çš„æ–‡ä»¶å†…å®¹ã€‚

    :param style: "emoji" ä½¿ç”¨ ğŸ“‚/ğŸ“œ å‰ç¼€; "tree" ä½¿ç”¨æ ‘å½¢å­—ç¬¦ (â”œâ”€, â””â”€)ã€‚
    :param include_content: False æ—¶ä»…è¾“å‡ºç›®å½•ç»“æ„,ä¸é™„å¸¦æ–‡ä»¶å†…å®¹ã€‚
    """
    encodings = encodings or DEFAULT_ENCODING_CANDIDATES
    tree_lines = []
    content_lines = []
    base_path = Path(root_path)

    cli_patterns = set(user_exclude)
    file_patterns = _get_ignore_patterns(base_path, encodings)
    all_exclude_patterns = DEFAULT_EXCLUDE_PATTERNS.union(cli_patterns).union(file_patterns).union({'.dircatignore'})

    files_to_read = []

    if style == "emoji":
        # emoji æ¨¡å¼ï¼šä½¿ç”¨ os.walk
        for root, dirs, files in os.walk(base_path, topdown=True):
            current_path = Path(root)

            dirs[:] = [d for d in dirs if not _is_excluded(current_path / d, all_exclude_patterns, base_path)]
            files[:] = [f for f in files if not _is_excluded(current_path / f, all_exclude_patterns, base_path)]

            if len(dirs) + len(files) > max_items:
                rel_path = current_path.relative_to(base_path)
                tree_lines.append(f"--- æ–‡ä»¶å¤¹ '{rel_path}' å› ä¸ºåŒ…å«è¶…è¿‡ {max_items} ä¸ªé¡¹ç›®è€Œè¢«è·³è¿‡ ---\n")
                dirs[:] = []
                continue

            level = len(current_path.relative_to(base_path).parts)
            indent = ' ' * 4 * level
            if current_path != base_path:
                tree_lines.append(f"{indent}ğŸ“‚ {current_path.name}/\n")

            sub_indent = ' ' * 4 * (level + 1)
            for f_name in sorted(files):
                tree_lines.append(f"{sub_indent}ğŸ“œ {f_name}\n")
                files_to_read.append(current_path / f_name)
    else:
        # tree æ¨¡å¼ï¼šä½¿ç”¨é€’å½’å‡½æ•°
        tree_lines, files_to_read = _build_tree_recursive(
            base_path, base_path, all_exclude_patterns, max_items
        )

    if include_content and files_to_read:
        content_lines.append("\n--- æ–‡ä»¶å†…å®¹ ---\n\n")
        for file_path in files_to_read:
            content_lines.append(_read_file_content(file_path, base_path, encodings))

    return "".join(tree_lines) + "".join(content_lines)

def main():
    parser = argparse.ArgumentParser(
        description="å°†ç›®å½•ç»“æ„å’Œæ–‡ä»¶å†…å®¹å¤åˆ¶åˆ°å‰ªåˆ‡æ¿æˆ–è¾“å‡ºåˆ°æ–‡ä»¶ï¼Œä»¥ä¾¿ç»™ AI è¿›è¡Œåˆ†æã€‚",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument(
        'path',
        nargs='?',
        default='.',
        help="è¦å¤„ç†çš„ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ã€‚"
    )
    parser.add_argument(
        '-n', '--exclude',
        nargs='*',
        default=[],
        help="æ°¸ä¹…æ·»åŠ å¿½ç•¥è§„åˆ™åˆ° .dircatignore æ–‡ä»¶ä¸­ã€‚"
    )
    parser.add_argument(
        '-i', '--ignore-temp',
        nargs='*',
        default=[],
        help="ä¸´æ—¶å¿½ç•¥æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ï¼Œä»…å¯¹æœ¬æ¬¡è¿è¡Œç”Ÿæ•ˆã€‚"
    )
    parser.add_argument(
        '--max-items',
        type=int,
        default=20,
        help="å¦‚æœä¸€ä¸ªæ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶å’Œå­æ–‡ä»¶å¤¹æ€»æ•°è¶…è¿‡æ­¤æ•°é‡ï¼Œåˆ™è·³è¿‡è¯¥æ–‡ä»¶å¤¹ã€‚é»˜è®¤å€¼ä¸º 20ã€‚"
    )
    parser.add_argument(
        '--style',
        choices=['emoji', 'tree'],
        default='tree',
        help=(
            "ç›®å½•æ˜¾ç¤ºæ ·å¼: "
            "emoji = ä½¿ç”¨ ğŸ“‚/ğŸ“œ å‰ç¼€; "
            "tree = ä½¿ç”¨ ASCII æ ‘å½¢ (â”œâ”€â”€, â””â”€â”€)ã€‚é»˜è®¤: emojiã€‚"
        )
    )
    parser.add_argument(
        '-t','--tree-only',
        action='store_true',
        help="åªæ˜¾ç¤ºç›®å½•ç»“æ„(ç±»ä¼¼ tree å‘½ä»¤), ä¸åŒ…å«æ–‡ä»¶å†…å®¹ã€‚"
    )
    parser.add_argument(
        '-o', '--output',
        type=str,
        default=None,
        help="æŒ‡å®šè¾“å‡ºæ–‡ä»¶çš„è·¯å¾„ã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™é»˜è®¤å¤åˆ¶åˆ°å‰ªåˆ‡æ¿ã€‚"
    )

    args = parser.parse_args()
    target_path = Path(args.path).resolve()

    encoding_candidates = DEFAULT_ENCODING_CANDIDATES

    if args.exclude:
        ignore_file_path = target_path / '.dircatignore'
        newly_added = []
        
        try:
            existing_patterns = set()
            file_exists = ignore_file_path.is_file()
            active_encoding = encoding_candidates[0]

            if file_exists:
                for encoding in _prepare_encoding_sequence(ignore_file_path, encoding_candidates):
                    try:
                        existing_content = ignore_file_path.read_text(encoding=encoding)
                        existing_patterns = set(line.strip() for line in existing_content.splitlines() if line.strip())
                        active_encoding = encoding
                        break
                    except UnicodeDecodeError:
                        continue
                # å¦‚æœå…¨éƒ¨è§£ç å¤±è´¥,existing_patterns ä¿æŒä¸ºç©º,ä½¿ç”¨é¦–é€‰ç¼–ç å†™å…¥

            patterns_to_add = []
            for pattern in args.exclude:
                pattern = pattern.strip()
                if pattern and pattern not in existing_patterns:
                    patterns_to_add.append(pattern)
                    newly_added.append(pattern)

            if patterns_to_add:
                file_size = ignore_file_path.stat().st_size if file_exists else 0
                with open(ignore_file_path, 'a', encoding=active_encoding) as f:
                    if file_size > 0:
                        f.write('\n')
                    f.write('\n'.join(patterns_to_add))
                print("å·²ç»å°†è§„åˆ™è‡ªåŠ¨å†™å…¥ .dircatignore æ–‡ä»¶")
        except IOError as e:
            print(f"è­¦å‘Šï¼šæ— æ³•å†™å…¥ .dircatignore æ–‡ä»¶: {e}")

    try:
        # å°†ä¸´æ—¶å¿½ç•¥è§„åˆ™ä¼ é€’ç»™ç”Ÿæˆå‡½æ•°
        structure = generate_tree_output(
            target_path,
            args.ignore_temp,
            args.max_items,
            encoding_candidates,
            style=args.style,
            include_content=not args.tree_only,
        )
        
        if args.output:
            # å¦‚æœæŒ‡å®šäº†è¾“å‡ºæ–‡ä»¶
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(structure)
            print(f"å·²æˆåŠŸä¿å­˜åˆ°æ–‡ä»¶: {args.output}")
        else:
            # å¦åˆ™ï¼Œå°è¯•å¤åˆ¶åˆ°å‰ªåˆ‡æ¿ï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€åˆ°æ–‡ä»¶
            try:
                pyperclip.copy(structure)
                print("å·²æˆåŠŸå¤åˆ¶åˆ°å‰ªåˆ‡æ¿ï¼")
            except pyperclip.PyperclipException:
                # å‰ªåˆ‡æ¿ä¸å¯ç”¨ï¼Œè‡ªåŠ¨ä¿å­˜åˆ°æ–‡ä»¶
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                fallback_filename = f"dircat_{timestamp}.txt"
                with open(fallback_filename, 'w', encoding='utf-8') as f:
                    f.write(structure)
                print("è­¦å‘Šï¼šæœªæ£€æµ‹åˆ°å‰ªåˆ‡æ¿ç¯å¢ƒã€‚")
                print(f"è¾“å‡ºå·²è‡ªåŠ¨ä¿å­˜åˆ°æ–‡ä»¶: {fallback_filename}")

    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æŒ‡å®šçš„è·¯å¾„ '{target_path}'")
    except Exception as e:
        print(f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")


if __name__ == "__main__":
    main()